import cv2
import os
import time
import json
import numpy as np
from detector import ObjectDetector  # ëª¨ë¸ë¡œ ê°ì§€í•´ì£¼ëŠ” í´ë˜ìŠ¤
from counter import DetectionCounter  # ê°ì§€ íšŸìˆ˜ë¥¼ ì„¸ëŠ” í´ë˜ìŠ¤
from visualizer import draw_boxes, draw_status, draw_counts  # í™”ë©´ì— ê·¸ë ¤ì£¼ëŠ” í•¨ìˆ˜ë“¤

# ğŸ¥ ì˜ìƒ íŒŒì¼ ì‚¬ìš© (ê¸°ë³¸)
VIDEO_PATH = "input_video.mp4"
cap = cv2.VideoCapture(VIDEO_PATH)

#ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—°ë‹¤
cap = cv2.VideoCapture(VIDEO_PATH)

# # ğŸ“¸ ì‹¤ì‹œê°„ ìº  ì‚¬ìš©í•˜ë ¤ë©´ ì•„ë˜ ì£¼ì„ í•´ì œí•˜ì„¸ìš”
# cap = cv2.VideoCapture(0)

# # ì¹´ë©”ë¼ ì¸í’‹ í¬ë©§ì„ MJPG ë¡œ ì„¤ì •
# fourcc = cv2.VideoWriter_fourcc(*'MJPG')
# if not cap.set(cv2.CAP_PROP_FOURCC, fourcc):
#     print("Failed to set FOURCC to MJPG.")

# # ì¹´ë©”ë¼ í•´ìƒë„ ì„¤ì •
# cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)
# cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)
# print(f"Resolution = {cap.get(cv2.CAP_PROP_FRAME_WIDTH)}x{cap.get(cv2.CAP_PROP_FRAME_HEIGHT)},FPS = {cap.get(cv2.CAP_PROP_FPS)}")

# ì°½ ìš°ì„ ìˆœìœ„
cv2.imshow("Status", np.zeros((200, 300, 3), dtype=np.uint8))
time.sleep(0.3)
os.system("wmctrl -r 'Status' -b add,above")


cv2.imshow("Counts", np.zeros((200, 300, 3), dtype=np.uint8))
time.sleep(0.3)
os.system("wmctrl -r 'Counts' -b add,above")

# ê°ì§€í•  ë¼ë²¨(ì¢…ë¥˜)
class_labels = ["m-on", "m-off", "l-on", "l-off", "not"]

# config.jsonì—ì„œ ê¸°ì¤€ê°’(ì‹ ë¢°ë„ ì„ê³„ê°’)ì„ ì½ê¸°
with open("config.json") as f:
    config = json.load(f)
CONFIDENCE_THRESHOLD = config.get("confidence_threshold", 0.7)

# ê°ì²´ ê°ì§€ê¸°ì™€ ì¹´ìš´í„°ë¥¼ ë§Œë“ ë‹¤
detector = ObjectDetector("openvino.xml", device="GPU")
counter = DetectionCounter(class_labels)

# ì²˜ìŒì—” WORKING ìƒíƒœ (ì•„ë¬´ ê²ƒë„ ê°ì§€ ì•ˆ ë¨)
status_text = "WORKING"
status_color = (255, 255, 0)  # ë…¸ë€ìƒ‰
status_start_time = 0
status_hold_duration = 3  # ìƒíƒœ ìœ ì§€ ì‹œê°„ (ì´ˆ)


while cap.isOpened():
    ret, frame = cap.read()

    # ì˜ìƒì´ ëë‚˜ë©´ ì²˜ìŒìœ¼ë¡œ ëŒì•„ê° (ë°˜ë³µ ì¬ìƒ)
    if not ret:
        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
        continue

    current_time = time.time()

    # ëª¨ë¸ë¡œ ê°ì§€ë¥¼ ì‹¤í–‰í•œë‹¤
    boxes_raw, labels_raw, scale, pad_left, pad_top = detector.infer(frame)

    combined = []
    detected_classes_in_frame = set()  # í˜„ì¬ ê°ì§€ëœ í´ë˜ìŠ¤ë“¤
    detected_now = None  # PASS ë˜ëŠ” NONPASS ì €ì¥í•  ë³€ìˆ˜

    # ê°ì§€ëœ ë°•ìŠ¤ë“¤ í•˜ë‚˜ì”© í™•ì¸
    for i in range(len(boxes_raw)):
        if np.all(boxes_raw[i] == 0):  # ë°•ìŠ¤ê°€ ì—†ë‹¤ë©´ ê±´ë„ˆëœ€
            continue
        x1, y1, x2, y2, conf = boxes_raw[i]
        class_id = int(labels_raw[i])
        class_name = class_labels[class_id]

        # l-onì€ ì¡°ê¸ˆ ë” ì ìˆ˜ ì˜¬ë ¤ì¤Œ
        if class_id == 2:
            conf *= 1.1

        # í´ë˜ìŠ¤ë³„ ê¸°ì¤€ í™•ì¸
        threshold = detector.custom_thresholds.get(class_id, CONFIDENCE_THRESHOLD)
        if conf < threshold:
            continue

        # ë°•ìŠ¤ ì¢Œí‘œë¥¼ ì›ë˜ í¬ê¸°ë¡œ ë‹¤ì‹œ ë§ì¶¤
        x1 = (x1 - pad_left) / scale
        y1 = (y1 - pad_top) / scale
        x2 = (x2 - pad_left) / scale
        y2 = (y2 - pad_top) / scale

        # ë„ˆë¬´ ì‘ê±°ë‚˜ ì´ìƒí•œ ìœ„ì¹˜ëŠ” ê±´ë„ˆëœ€
        box_width = x2 - x1
        box_height = y2 - y1
        if box_width < 5 or box_height < 5:
            continue
        if x1 < 0 or y1 < 0 or x2 > frame.shape[1] or y2 > frame.shape[0]:
            continue
        if class_id == 4 and (
            box_width > frame.shape[1] * 0.5 or box_height > frame.shape[0] * 0.5
        ):
            continue

        # ì‚¬ìš©í•  ë°•ìŠ¤ì— ì¶”ê°€
        combined.append([x1, y1, x2, y2, conf, class_id])
        detected_classes_in_frame.add(class_name)

        # ì–´ë–¤ ìƒíƒœì¸ì§€ ì €ì¥ (PASS ë˜ëŠ” NONPASS)
        if class_id in [0, 2]:  # m-on, l-on
            detected_now = "PASS"
        elif class_id in [1, 3, 4]:  # m-off, l-off, not
            detected_now = "NONPASS"

    # ìƒíƒœë¥¼ ë³€ê²½í• ì§€ í™•ì¸
    if detected_now:
        status_text = detected_now
        status_color = (0, 255, 0) if detected_now == "PASS" else (0, 0, 255)
        status_start_time = current_time
    elif current_time - status_start_time > status_hold_duration:
        status_text = "WORKING"
        status_color = (255, 255, 0)

    # ê°ì§€ëœ ê²ƒë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ì¹´ìš´íŠ¸ ì—…ë°ì´íŠ¸
    counter.update(detected_classes_in_frame)

    # ê²°ê³¼ í™”ë©´ ê·¸ë¦¬ê¸°
    result_img = draw_boxes(
        frame.copy(), combined, class_labels, threshold=CONFIDENCE_THRESHOLD
    )
    decision_img = draw_status(status_text, status_color)
    count_img = draw_counts(counter.class_counts)

    # ì°½ ë°°ì¹˜ ì¡°ì •
    cv2.namedWindow("Detection", cv2.WINDOW_NORMAL | cv2.WINDOW_GUI_NORMAL)
    cv2.setWindowProperty("Detection", cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)
    # cv2.moveWindow("Detection", 0, 0)

    cv2.namedWindow("Status", cv2.WINDOW_NORMAL | cv2.WINDOW_GUI_NORMAL)
    cv2.moveWindow("Status", 1600, 100)

    cv2.namedWindow("Counts", cv2.WINDOW_NORMAL | cv2.WINDOW_GUI_NORMAL)
    cv2.moveWindow("Counts", 1600, 380)

    # ê°ê°ì˜ ì°½ì— ë”°ë¡œ ë³´ì—¬ì¤Œ
    cv2.imshow("Detection", cv2.cvtColor(result_img, cv2.COLOR_RGB2BGR))  # ë°•ìŠ¤ ë³´ì—¬ì¤Œ
    cv2.imshow("Status", decision_img)  # PASS/NONPASS
    cv2.imshow("Counts", count_img)  # ëª‡ ë²ˆ ê°ì§€ëëŠ”ì§€

    # ê°ê°ì˜ ì°½ Size
    # WINDOW_W1 = 1800
    # WINDOW_H1 = 800
    WINDOW_W2 = 352
    WINDOW_H2 = 240

    # cv2.resizeWindow("Detection", WINDOW_W1, WINDOW_H1)
    cv2.resizeWindow("Status", WINDOW_W2, WINDOW_H2)
    cv2.resizeWindow("Counts", WINDOW_W2, WINDOW_H2)

    # që¥¼ ëˆ„ë¥´ë©´ ì¢…ë£Œ
    if cv2.waitKey(1) & 0xFF == ord("q"):
        break
    
# ì˜ìƒ ëë‚˜ë©´ ì°½ ë‹«ê¸°
cap.release()
cv2.destroyAllWindows()
